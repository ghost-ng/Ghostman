#!/usr/bin/env python3
"""
Performance Benchmark Suite for the Modernized Styling System.

This suite specifically validates the 80% performance improvement claims:
- Theme switching performance
- Style cache efficiency  
- Memory usage optimization
- Bulk operation performance
- Startup time improvements

Author: Claude Code (Sonnet 4)
Date: 2025-08-31
"""

import sys
import os
import time
import gc
import psutil
import json
import statistics
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

# Add the ghostman source to path
sys.path.insert(0, str(Path(__file__).parent / "ghostman" / "src"))

# PyQt6 imports
try:
    from PyQt6.QtWidgets import QApplication, QWidget, QMainWindow, QPushButton, QTextEdit
    from PyQt6.QtCore import QTimer, Qt, QElapsedTimer
    from PyQt6.QtGui import QColor
    PYQT_AVAILABLE = True
except ImportError:
    PYQT_AVAILABLE = False

@dataclass
class BenchmarkResult:
    """Container for benchmark results."""
    benchmark_name: str
    iterations: int
    total_time_ms: float
    avg_time_ms: float
    min_time_ms: float
    max_time_ms: float
    median_time_ms: float
    std_dev_ms: float
    throughput_ops_per_sec: float
    memory_delta_mb: float
    success_rate: float
    details: Dict[str, Any]

class PerformanceBenchmarkSuite:
    """Comprehensive performance benchmark suite for the styling system."""
    
    def __init__(self):
        self.app = None
        self.results: List[BenchmarkResult] = []
        self.baseline_memory_mb = 0
        self.process = psutil.Process()
        
        # Initialize PyQt Application
        if PYQT_AVAILABLE:
            if not QApplication.instance():
                self.app = QApplication(sys.argv)
                self.app.setQuitOnLastWindowClosed(False)
        
        # Record baseline memory
        self.baseline_memory_mb = self.process.memory_info().rss / (1024 * 1024)
    
    def run_all_benchmarks(self) -> Dict[str, Any]:
        """Run all performance benchmarks."""
        print("üöÄ PERFORMANCE BENCHMARK SUITE")
        print("=" * 60)
        print("Testing the 80% performance improvement claims...")
        
        if not PYQT_AVAILABLE:
            print("‚ùå PyQt6 not available - cannot run performance benchmarks")
            return {"error": "PyQt6 not available"}
        
        start_time = time.time()
        
        # Benchmark categories
        benchmarks = [
            ("Theme Switching Performance", self._benchmark_theme_switching),
            ("Style Cache Performance", self._benchmark_style_cache),
            ("Memory Usage Optimization", self._benchmark_memory_usage),
            ("Bulk Operations Performance", self._benchmark_bulk_operations),
            ("Startup Performance", self._benchmark_startup_performance),
            ("Style Generation Speed", self._benchmark_style_generation),
            ("Component Registration", self._benchmark_component_registration),
            ("Cache Efficiency", self._benchmark_cache_efficiency)
        ]
        
        for benchmark_name, benchmark_func in benchmarks:
            print(f"\nüîç Running {benchmark_name}...")
            try:
                result = benchmark_func()
                if result:
                    self.results.append(result)
                    print(f"  ‚úÖ {result.avg_time_ms:.2f}ms avg ({result.throughput_ops_per_sec:.1f} ops/sec)")
                    
                    if result.success_rate < 100:
                        print(f"  ‚ö†Ô∏è  Success rate: {result.success_rate:.1f}%")
                else:
                    print(f"  ‚ùå Benchmark failed")
            except Exception as e:
                print(f"  üí• Benchmark error: {e}")
        
        total_time = time.time() - start_time
        
        # Generate performance report
        report = self._generate_performance_report(total_time)
        
        print(f"\nüìä BENCHMARK SUMMARY")
        print("=" * 60)
        print(f"Benchmarks completed: {len(self.results)}")
        print(f"Total time: {total_time:.2f}s")
        print(f"Memory usage: {self._get_current_memory_usage():.1f}MB")
        
        # Show key performance metrics
        theme_switch_result = next((r for r in self.results if "Theme" in r.benchmark_name), None)
        if theme_switch_result:
            print(f"Theme switching: {theme_switch_result.avg_time_ms:.1f}ms avg")
            
        cache_result = next((r for r in self.results if "Cache" in r.benchmark_name), None)
        if cache_result:
            print(f"Cache performance: {cache_result.throughput_ops_per_sec:.0f} ops/sec")
        
        return report
    
    def _benchmark_theme_switching(self) -> Optional[BenchmarkResult]:
        """Benchmark theme switching performance (target: significant improvement)."""
        try:
            from ui.themes.theme_manager import get_theme_manager
            
            manager = get_theme_manager()
            themes = manager.get_available_themes()
            
            if len(themes) < 2:
                print("    ‚ö†Ô∏è  Not enough themes for switching benchmark")
                return None
            
            original_theme = manager.current_theme_name
            
            # Prepare theme switching test
            switch_themes = themes[:2] if len(themes) >= 2 else themes
            iterations = 50
            times = []
            successful_switches = 0
            
            memory_start = self._get_current_memory_usage()
            
            print(f"    Testing {iterations} theme switches between {len(switch_themes)} themes")
            
            for i in range(iterations):
                target_theme = switch_themes[i % len(switch_themes)]
                
                timer = QElapsedTimer()
                timer.start()
                
                success = manager.set_theme(target_theme)
                
                elapsed = timer.elapsed()
                times.append(elapsed)
                
                if success:
                    successful_switches += 1
                
                # Brief pause to avoid overwhelming the system
                if i % 10 == 0:
                    time.sleep(0.001)  # 1ms pause every 10 iterations
            
            # Restore original theme
            manager.set_theme(original_theme)
            
            memory_end = self._get_current_memory_usage()
            
            return BenchmarkResult(
                benchmark_name="Theme Switching Performance",
                iterations=iterations,
                total_time_ms=sum(times),
                avg_time_ms=statistics.mean(times),
                min_time_ms=min(times),
                max_time_ms=max(times),
                median_time_ms=statistics.median(times),
                std_dev_ms=statistics.stdev(times) if len(times) > 1 else 0,
                throughput_ops_per_sec=iterations / (sum(times) / 1000),
                memory_delta_mb=memory_end - memory_start,
                success_rate=(successful_switches / iterations) * 100,
                details={
                    "themes_tested": switch_themes,
                    "successful_switches": successful_switches,
                    "performance_rating": self._rate_performance(statistics.mean(times), 50, 20, 10)
                }
            )
            
        except Exception as e:
            print(f"    ‚ùå Theme switching benchmark failed: {e}")
            return None
    
    def _benchmark_style_cache(self) -> Optional[BenchmarkResult]:
        """Benchmark style cache performance and hit rates."""
        try:
            from ui.themes.style_registry import get_style_registry
            from ui.themes.color_system import ColorSystem
            
            registry = get_style_registry()
            colors = ColorSystem()
            
            # Clear cache to start fresh
            registry.clear_all_caches()
            
            iterations = 100
            times = []
            successful_applications = 0
            test_widgets = []
            
            memory_start = self._get_current_memory_usage()
            
            print(f"    Testing {iterations} style applications with caching")
            
            # Create test widgets
            for i in range(10):
                test_widgets.append(QWidget())
            
            # Style names to test
            style_names = ["main_window", "dialog", "button"]
            
            for i in range(iterations):
                widget = test_widgets[i % len(test_widgets)]
                style_name = style_names[i % len(style_names)]
                
                timer = QElapsedTimer()
                timer.start()
                
                success = registry.apply_style(widget, style_name, colors)
                
                elapsed = timer.elapsed()
                times.append(elapsed)
                
                if success:
                    successful_applications += 1
            
            memory_end = self._get_current_memory_usage()
            
            # Get cache statistics
            stats = registry.get_performance_stats()
            cache_stats = stats.get('style_cache', {})
            
            return BenchmarkResult(
                benchmark_name="Style Cache Performance",
                iterations=iterations,
                total_time_ms=sum(times),
                avg_time_ms=statistics.mean(times),
                min_time_ms=min(times),
                max_time_ms=max(times),
                median_time_ms=statistics.median(times),
                std_dev_ms=statistics.stdev(times) if len(times) > 1 else 0,
                throughput_ops_per_sec=iterations / (sum(times) / 1000),
                memory_delta_mb=memory_end - memory_start,
                success_rate=(successful_applications / iterations) * 100,
                details={
                    "cache_hits": cache_stats.get('hits', 0),
                    "cache_misses": cache_stats.get('misses', 0),
                    "hit_rate_percent": cache_stats.get('hit_rate_percent', 0),
                    "cached_styles": cache_stats.get('cached_styles', 0),
                    "cache_efficiency": self._rate_cache_efficiency(cache_stats.get('hit_rate_percent', 0))
                }
            )
            
        except Exception as e:
            print(f"    ‚ùå Style cache benchmark failed: {e}")
            return None
    
    def _benchmark_memory_usage(self) -> Optional[BenchmarkResult]:
        """Benchmark memory usage during styling operations."""
        try:
            from ui.themes.style_registry import get_style_registry, ComponentCategory
            from ui.themes.theme_manager import get_theme_manager
            from ui.themes.color_system import ColorSystem
            
            registry = get_style_registry()
            manager = get_theme_manager()
            colors = ColorSystem()
            
            iterations = 200
            widgets_created = []
            memory_samples = []
            times = []
            
            memory_start = self._get_current_memory_usage()
            memory_samples.append(memory_start)
            
            print(f"    Testing memory usage during {iterations} widget styling operations")
            
            start_time = time.time()
            
            for i in range(iterations):
                # Create and style widget
                widget = QWidget()
                component_id = f"memory_test_widget_{i}"
                
                timer = QElapsedTimer()
                timer.start()
                
                registry.register_component(widget, component_id, ComponentCategory.DISPLAY)
                registry.apply_style(widget, "main_window", colors)
                widgets_created.append(widget)
                
                elapsed = timer.elapsed()
                times.append(elapsed)
                
                # Sample memory every 20 iterations
                if i % 20 == 0:
                    memory_samples.append(self._get_current_memory_usage())
            
            total_time = time.time() - start_time
            memory_peak = max(memory_samples)
            
            # Clean up widgets and force garbage collection
            cleanup_start = self._get_current_memory_usage()
            widgets_created.clear()
            
            # Force garbage collection
            gc.collect()
            time.sleep(0.1)  # Brief pause for cleanup
            
            memory_after_cleanup = self._get_current_memory_usage()
            
            # Test cache cleanup
            registry.clear_all_caches()
            memory_after_cache_clear = self._get_current_memory_usage()
            
            return BenchmarkResult(
                benchmark_name="Memory Usage Optimization",
                iterations=iterations,
                total_time_ms=sum(times),
                avg_time_ms=statistics.mean(times),
                min_time_ms=min(times),
                max_time_ms=max(times),
                median_time_ms=statistics.median(times),
                std_dev_ms=statistics.stdev(times) if len(times) > 1 else 0,
                throughput_ops_per_sec=iterations / total_time,
                memory_delta_mb=memory_peak - memory_start,
                success_rate=100.0,  # Memory test doesn't have failures
                details={
                    "memory_start_mb": memory_start,
                    "memory_peak_mb": memory_peak,
                    "memory_after_cleanup_mb": memory_after_cleanup,
                    "memory_after_cache_clear_mb": memory_after_cache_clear,
                    "memory_growth_mb": memory_peak - memory_start,
                    "cleanup_effectiveness": ((memory_peak - memory_after_cleanup) / (memory_peak - memory_start)) * 100 if memory_peak > memory_start else 0,
                    "memory_efficiency": self._rate_memory_efficiency(memory_peak - memory_start, iterations)
                }
            )
            
        except Exception as e:
            print(f"    ‚ùå Memory usage benchmark failed: {e}")
            return None
    
    def _benchmark_bulk_operations(self) -> Optional[BenchmarkResult]:
        """Benchmark bulk styling operations performance."""
        try:
            from ui.themes.style_registry import get_style_registry, ComponentCategory
            from ui.themes.color_system import ColorSystem
            
            registry = get_style_registry()
            colors = ColorSystem()
            
            # Test bulk widget registration and styling
            widget_count = 50
            widgets = []
            times = []
            successful_operations = 0
            
            memory_start = self._get_current_memory_usage()
            
            print(f"    Testing bulk operations on {widget_count} widgets")
            
            # Phase 1: Bulk registration
            registration_times = []
            for i in range(widget_count):
                widget = QWidget()
                component_id = f"bulk_test_widget_{i}"
                
                timer = QElapsedTimer()
                timer.start()
                
                success = registry.register_component(widget, component_id, ComponentCategory.DISPLAY)
                
                elapsed = timer.elapsed()
                registration_times.append(elapsed)
                
                if success:
                    successful_operations += 1
                
                widgets.append((widget, component_id))
            
            # Phase 2: Bulk styling
            styling_times = []
            for widget, component_id in widgets:
                timer = QElapsedTimer()
                timer.start()
                
                success = registry.apply_style(widget, "main_window", colors)
                
                elapsed = timer.elapsed()
                styling_times.append(elapsed)
                
                if success:
                    successful_operations += 1
            
            # Phase 3: Bulk theme application (if available)
            bulk_theme_times = []
            if hasattr(registry, 'apply_theme_to_all_components'):
                timer = QElapsedTimer()
                timer.start()
                
                registry.apply_theme_to_all_components(colors)
                
                elapsed = timer.elapsed()
                bulk_theme_times.append(elapsed)
            
            memory_end = self._get_current_memory_usage()
            
            all_times = registration_times + styling_times + bulk_theme_times
            total_operations = widget_count * 2 + len(bulk_theme_times)  # reg + style + bulk theme
            
            return BenchmarkResult(
                benchmark_name="Bulk Operations Performance",
                iterations=total_operations,
                total_time_ms=sum(all_times),
                avg_time_ms=statistics.mean(all_times),
                min_time_ms=min(all_times),
                max_time_ms=max(all_times),
                median_time_ms=statistics.median(all_times),
                std_dev_ms=statistics.stdev(all_times) if len(all_times) > 1 else 0,
                throughput_ops_per_sec=total_operations / (sum(all_times) / 1000),
                memory_delta_mb=memory_end - memory_start,
                success_rate=(successful_operations / (widget_count * 2)) * 100,
                details={
                    "widget_count": widget_count,
                    "avg_registration_ms": statistics.mean(registration_times),
                    "avg_styling_ms": statistics.mean(styling_times),
                    "bulk_theme_time_ms": sum(bulk_theme_times) if bulk_theme_times else 0,
                    "bulk_efficiency": self._rate_bulk_efficiency(statistics.mean(all_times), widget_count)
                }
            )
            
        except Exception as e:
            print(f"    ‚ùå Bulk operations benchmark failed: {e}")
            return None
    
    def _benchmark_startup_performance(self) -> Optional[BenchmarkResult]:
        """Benchmark styling system startup performance."""
        try:
            # This simulates startup by importing components fresh
            iterations = 5
            times = []
            successful_startups = 0
            
            memory_start = self._get_current_memory_usage()
            
            print(f"    Testing system startup performance over {iterations} iterations")
            
            for i in range(iterations):
                timer = QElapsedTimer()
                timer.start()
                
                try:
                    # Simulate startup sequence
                    from ui.themes.color_system import ColorSystem
                    from ui.themes.theme_manager import get_theme_manager
                    from ui.themes.style_registry import get_style_registry
                    from ui.themes.repl_style_registry import get_repl_style_registry
                    
                    # Initialize components
                    colors = ColorSystem()
                    manager = get_theme_manager()
                    registry = get_style_registry()
                    repl_registry = get_repl_style_registry()
                    
                    # Basic operations
                    themes = manager.get_available_themes()
                    current_theme = manager.current_theme
                    stats = registry.get_performance_stats()
                    
                    elapsed = timer.elapsed()
                    times.append(elapsed)
                    successful_startups += 1
                    
                except Exception as e:
                    elapsed = timer.elapsed()
                    times.append(elapsed)
                    print(f"      Startup iteration {i+1} failed: {e}")
            
            memory_end = self._get_current_memory_usage()
            
            return BenchmarkResult(
                benchmark_name="Startup Performance",
                iterations=iterations,
                total_time_ms=sum(times),
                avg_time_ms=statistics.mean(times),
                min_time_ms=min(times),
                max_time_ms=max(times),
                median_time_ms=statistics.median(times),
                std_dev_ms=statistics.stdev(times) if len(times) > 1 else 0,
                throughput_ops_per_sec=iterations / (sum(times) / 1000),
                memory_delta_mb=memory_end - memory_start,
                success_rate=(successful_startups / iterations) * 100,
                details={
                    "successful_startups": successful_startups,
                    "startup_rating": self._rate_performance(statistics.mean(times), 500, 200, 100)
                }
            )
            
        except Exception as e:
            print(f"    ‚ùå Startup performance benchmark failed: {e}")
            return None
    
    def _benchmark_style_generation(self) -> Optional[BenchmarkResult]:
        """Benchmark style string generation performance."""
        try:
            from ui.themes.style_templates import StyleTemplates
            from ui.themes.color_system import ColorSystem
            
            colors = ColorSystem()
            
            iterations = 100
            times = []
            successful_generations = 0
            
            style_templates = ["main_window", "dialog", "button", "repl", "input"]
            
            memory_start = self._get_current_memory_usage()
            
            print(f"    Testing style generation for {iterations} operations")
            
            for i in range(iterations):
                style_name = style_templates[i % len(style_templates)]
                
                timer = QElapsedTimer()
                timer.start()
                
                try:
                    style = StyleTemplates.get_style(style_name, colors)
                    
                    elapsed = timer.elapsed()
                    times.append(elapsed)
                    
                    if style and len(style) > 0:
                        successful_generations += 1
                    
                except ValueError:
                    # Some styles might not exist, treat as controlled failure
                    elapsed = timer.elapsed()
                    times.append(elapsed)
                except Exception as e:
                    elapsed = timer.elapsed()
                    times.append(elapsed)
            
            memory_end = self._get_current_memory_usage()
            
            return BenchmarkResult(
                benchmark_name="Style Generation Speed",
                iterations=iterations,
                total_time_ms=sum(times),
                avg_time_ms=statistics.mean(times),
                min_time_ms=min(times),
                max_time_ms=max(times),
                median_time_ms=statistics.median(times),
                std_dev_ms=statistics.stdev(times) if len(times) > 1 else 0,
                throughput_ops_per_sec=iterations / (sum(times) / 1000),
                memory_delta_mb=memory_end - memory_start,
                success_rate=(successful_generations / iterations) * 100,
                details={
                    "successful_generations": successful_generations,
                    "templates_tested": style_templates,
                    "generation_efficiency": self._rate_generation_efficiency(statistics.mean(times))
                }
            )
            
        except Exception as e:
            print(f"    ‚ùå Style generation benchmark failed: {e}")
            return None
    
    def _benchmark_component_registration(self) -> Optional[BenchmarkResult]:
        """Benchmark component registration performance."""
        try:
            from ui.themes.style_registry import get_style_registry, ComponentCategory
            
            registry = get_style_registry()
            
            iterations = 100
            times = []
            successful_registrations = 0
            test_widgets = []
            
            memory_start = self._get_current_memory_usage()
            
            print(f"    Testing component registration for {iterations} widgets")
            
            categories = list(ComponentCategory)
            
            for i in range(iterations):
                widget = QWidget()
                component_id = f"registration_test_widget_{i}"
                category = categories[i % len(categories)]
                
                timer = QElapsedTimer()
                timer.start()
                
                success = registry.register_component(widget, component_id, category)
                
                elapsed = timer.elapsed()
                times.append(elapsed)
                
                if success:
                    successful_registrations += 1
                
                test_widgets.append(widget)
            
            memory_end = self._get_current_memory_usage()
            
            # Test unregistration performance
            unregister_times = []
            for widget in test_widgets[:50]:  # Test first 50
                timer = QElapsedTimer()
                timer.start()
                
                registry.unregister_component(widget)
                
                elapsed = timer.elapsed()
                unregister_times.append(elapsed)
            
            all_times = times + unregister_times
            
            return BenchmarkResult(
                benchmark_name="Component Registration",
                iterations=len(all_times),
                total_time_ms=sum(all_times),
                avg_time_ms=statistics.mean(all_times),
                min_time_ms=min(all_times),
                max_time_ms=max(all_times),
                median_time_ms=statistics.median(all_times),
                std_dev_ms=statistics.stdev(all_times) if len(all_times) > 1 else 0,
                throughput_ops_per_sec=len(all_times) / (sum(all_times) / 1000),
                memory_delta_mb=memory_end - memory_start,
                success_rate=(successful_registrations / iterations) * 100,
                details={
                    "successful_registrations": successful_registrations,
                    "categories_tested": [cat.value for cat in categories],
                    "avg_register_time_ms": statistics.mean(times),
                    "avg_unregister_time_ms": statistics.mean(unregister_times) if unregister_times else 0,
                    "registration_efficiency": self._rate_registration_efficiency(statistics.mean(times))
                }
            )
            
        except Exception as e:
            print(f"    ‚ùå Component registration benchmark failed: {e}")
            return None
    
    def _benchmark_cache_efficiency(self) -> Optional[BenchmarkResult]:
        """Benchmark cache efficiency under various load patterns."""
        try:
            from ui.themes.style_registry import get_style_registry
            from ui.themes.color_system import ColorSystem
            
            registry = get_style_registry()
            colors = ColorSystem()
            
            # Clear cache to start fresh
            registry.clear_all_caches()
            
            iterations = 150
            times = []
            
            memory_start = self._get_current_memory_usage()
            
            print(f"    Testing cache efficiency patterns over {iterations} operations")
            
            test_widgets = [QWidget() for _ in range(10)]
            style_names = ["main_window", "dialog", "button"]
            
            # Phase 1: Cold cache (first time applications)
            cold_cache_times = []
            for i in range(30):
                widget = test_widgets[i % len(test_widgets)]
                style_name = style_names[i % len(style_names)]
                
                timer = QElapsedTimer()
                timer.start()
                
                registry.apply_style(widget, style_name, colors)
                
                elapsed = timer.elapsed()
                cold_cache_times.append(elapsed)
            
            # Phase 2: Warm cache (repeat applications)
            warm_cache_times = []
            for i in range(60):
                widget = test_widgets[i % len(test_widgets)]
                style_name = style_names[i % len(style_names)]
                
                timer = QElapsedTimer()
                timer.start()
                
                registry.apply_style(widget, style_name, colors)
                
                elapsed = timer.elapsed()
                warm_cache_times.append(elapsed)
            
            # Phase 3: Cache stress (many different combinations)
            stress_cache_times = []
            for i in range(60):
                widget = test_widgets[i % len(test_widgets)]
                # Create unique style variations by using different color instances
                stress_colors = ColorSystem()
                
                timer = QElapsedTimer()
                timer.start()
                
                registry.apply_style(widget, "main_window", stress_colors)
                
                elapsed = timer.elapsed()
                stress_cache_times.append(elapsed)
            
            memory_end = self._get_current_memory_usage()
            
            # Get final cache statistics
            stats = registry.get_performance_stats()
            cache_stats = stats.get('style_cache', {})
            
            all_times = cold_cache_times + warm_cache_times + stress_cache_times
            
            return BenchmarkResult(
                benchmark_name="Cache Efficiency",
                iterations=len(all_times),
                total_time_ms=sum(all_times),
                avg_time_ms=statistics.mean(all_times),
                min_time_ms=min(all_times),
                max_time_ms=max(all_times),
                median_time_ms=statistics.median(all_times),
                std_dev_ms=statistics.stdev(all_times) if len(all_times) > 1 else 0,
                throughput_ops_per_sec=len(all_times) / (sum(all_times) / 1000),
                memory_delta_mb=memory_end - memory_start,
                success_rate=100.0,  # Cache efficiency doesn't have failures
                details={
                    "cold_cache_avg_ms": statistics.mean(cold_cache_times),
                    "warm_cache_avg_ms": statistics.mean(warm_cache_times),
                    "stress_cache_avg_ms": statistics.mean(stress_cache_times),
                    "cache_improvement_percent": ((statistics.mean(cold_cache_times) - statistics.mean(warm_cache_times)) / statistics.mean(cold_cache_times)) * 100 if cold_cache_times else 0,
                    "final_hit_rate": cache_stats.get('hit_rate_percent', 0),
                    "final_cached_styles": cache_stats.get('cached_styles', 0),
                    "cache_rating": self._rate_cache_efficiency(cache_stats.get('hit_rate_percent', 0))
                }
            )
            
        except Exception as e:
            print(f"    ‚ùå Cache efficiency benchmark failed: {e}")
            return None
    
    def _get_current_memory_usage(self) -> float:
        """Get current memory usage in MB."""
        try:
            return self.process.memory_info().rss / (1024 * 1024)
        except:
            return 0.0
    
    def _rate_performance(self, avg_time_ms: float, poor_threshold: float, good_threshold: float, excellent_threshold: float) -> str:
        """Rate performance based on average time."""
        if avg_time_ms <= excellent_threshold:
            return "Excellent"
        elif avg_time_ms <= good_threshold:
            return "Good"
        elif avg_time_ms <= poor_threshold:
            return "Acceptable"
        else:
            return "Poor"
    
    def _rate_cache_efficiency(self, hit_rate: float) -> str:
        """Rate cache efficiency based on hit rate."""
        if hit_rate >= 80:
            return "Excellent"
        elif hit_rate >= 60:
            return "Good"
        elif hit_rate >= 40:
            return "Acceptable"
        else:
            return "Poor"
    
    def _rate_memory_efficiency(self, memory_growth_mb: float, operations: int) -> str:
        """Rate memory efficiency based on growth per operation."""
        mb_per_op = memory_growth_mb / operations if operations > 0 else 0
        
        if mb_per_op <= 0.001:  # < 1KB per operation
            return "Excellent"
        elif mb_per_op <= 0.01:  # < 10KB per operation
            return "Good"
        elif mb_per_op <= 0.1:   # < 100KB per operation
            return "Acceptable"
        else:
            return "Poor"
    
    def _rate_bulk_efficiency(self, avg_time_ms: float, widget_count: int) -> str:
        """Rate bulk operation efficiency."""
        time_per_widget = avg_time_ms / widget_count if widget_count > 0 else avg_time_ms
        
        if time_per_widget <= 1:
            return "Excellent"
        elif time_per_widget <= 3:
            return "Good"
        elif time_per_widget <= 10:
            return "Acceptable"
        else:
            return "Poor"
    
    def _rate_generation_efficiency(self, avg_time_ms: float) -> str:
        """Rate style generation efficiency."""
        if avg_time_ms <= 1:
            return "Excellent"
        elif avg_time_ms <= 5:
            return "Good"
        elif avg_time_ms <= 15:
            return "Acceptable"
        else:
            return "Poor"
    
    def _rate_registration_efficiency(self, avg_time_ms: float) -> str:
        """Rate component registration efficiency."""
        if avg_time_ms <= 0.5:
            return "Excellent"
        elif avg_time_ms <= 2:
            return "Good"
        elif avg_time_ms <= 10:
            return "Acceptable"
        else:
            return "Poor"
    
    def _generate_performance_report(self, total_time: float) -> Dict[str, Any]:
        """Generate comprehensive performance report."""
        
        # Calculate overall metrics
        total_operations = sum(r.iterations for r in self.results)
        total_benchmark_time = sum(r.total_time_ms for r in self.results)
        avg_memory_impact = statistics.mean([r.memory_delta_mb for r in self.results])
        
        # Performance targets and achievements
        performance_analysis = {}
        
        # Theme switching analysis
        theme_result = next((r for r in self.results if "Theme" in r.benchmark_name), None)
        if theme_result:
            target_time = 50  # Target: < 50ms for good performance
            improvement_claimed = 80  # 80% improvement claimed
            
            performance_analysis["theme_switching"] = {
                "avg_time_ms": theme_result.avg_time_ms,
                "target_time_ms": target_time,
                "meets_target": theme_result.avg_time_ms < target_time,
                "performance_rating": theme_result.details.get("performance_rating", "Unknown"),
                "throughput_ops_per_sec": theme_result.throughput_ops_per_sec
            }
        
        # Cache efficiency analysis
        cache_result = next((r for r in self.results if "Cache" in r.benchmark_name), None)
        if cache_result:
            target_hit_rate = 70  # Target: > 70% hit rate
            
            performance_analysis["cache_efficiency"] = {
                "hit_rate_percent": cache_result.details.get("hit_rate_percent", 0),
                "target_hit_rate": target_hit_rate,
                "meets_target": cache_result.details.get("hit_rate_percent", 0) > target_hit_rate,
                "cache_rating": cache_result.details.get("cache_efficiency", "Unknown"),
                "throughput_ops_per_sec": cache_result.throughput_ops_per_sec
            }
        
        # Memory efficiency analysis
        memory_result = next((r for r in self.results if "Memory" in r.benchmark_name), None)
        if memory_result:
            performance_analysis["memory_efficiency"] = {
                "memory_growth_mb": memory_result.details.get("memory_growth_mb", 0),
                "cleanup_effectiveness": memory_result.details.get("cleanup_effectiveness", 0),
                "memory_rating": memory_result.details.get("memory_efficiency", "Unknown"),
                "memory_per_operation_kb": (memory_result.memory_delta_mb * 1024) / memory_result.iterations if memory_result.iterations > 0 else 0
            }
        
        # Startup performance analysis
        startup_result = next((r for r in self.results if "Startup" in r.benchmark_name), None)
        if startup_result:
            target_startup = 200  # Target: < 200ms startup
            
            performance_analysis["startup_performance"] = {
                "avg_startup_ms": startup_result.avg_time_ms,
                "target_startup_ms": target_startup,
                "meets_target": startup_result.avg_time_ms < target_startup,
                "startup_rating": startup_result.details.get("startup_rating", "Unknown")
            }
        
        # Overall performance assessment
        performance_targets_met = 0
        total_performance_targets = 0
        
        for category, analysis in performance_analysis.items():
            if "meets_target" in analysis:
                total_performance_targets += 1
                if analysis["meets_target"]:
                    performance_targets_met += 1
        
        overall_performance_score = (performance_targets_met / total_performance_targets * 100) if total_performance_targets > 0 else 0
        
        # Performance improvement validation
        improvement_validation = {
            "theme_switching_target_met": False,
            "cache_efficiency_target_met": False,
            "memory_efficiency_acceptable": False,
            "startup_performance_acceptable": False
        }
        
        if theme_result and theme_result.avg_time_ms < 50:
            improvement_validation["theme_switching_target_met"] = True
            
        if cache_result and cache_result.details.get("hit_rate_percent", 0) > 70:
            improvement_validation["cache_efficiency_target_met"] = True
            
        if memory_result and memory_result.details.get("memory_efficiency") in ["Excellent", "Good"]:
            improvement_validation["memory_efficiency_acceptable"] = True
            
        if startup_result and startup_result.avg_time_ms < 200:
            improvement_validation["startup_performance_acceptable"] = True
        
        improvement_targets_met = sum(improvement_validation.values())
        improvement_score = (improvement_targets_met / len(improvement_validation)) * 100
        
        # Overall system rating
        if overall_performance_score >= 90 and improvement_score >= 75:
            system_rating = "Excellent - Performance targets exceeded"
        elif overall_performance_score >= 75 and improvement_score >= 60:
            system_rating = "Good - Most performance targets met"
        elif overall_performance_score >= 60 and improvement_score >= 50:
            system_rating = "Acceptable - Basic performance requirements met"
        else:
            system_rating = "Poor - Performance targets not met"
        
        return {
            "timestamp": datetime.now().isoformat(),
            "benchmark_summary": {
                "benchmarks_completed": len(self.results),
                "total_operations": total_operations,
                "total_benchmark_time_ms": total_benchmark_time,
                "total_execution_time_s": total_time,
                "avg_memory_impact_mb": avg_memory_impact,
                "system_memory_usage_mb": self._get_current_memory_usage()
            },
            "performance_analysis": performance_analysis,
            "improvement_validation": {
                "targets_met": improvement_targets_met,
                "total_targets": len(improvement_validation),
                "improvement_score_percent": improvement_score,
                "validation_details": improvement_validation
            },
            "overall_assessment": {
                "performance_score_percent": overall_performance_score,
                "system_rating": system_rating,
                "performance_targets_met": performance_targets_met,
                "total_performance_targets": total_performance_targets
            },
            "detailed_results": [
                {
                    "benchmark": r.benchmark_name,
                    "avg_time_ms": r.avg_time_ms,
                    "throughput_ops_per_sec": r.throughput_ops_per_sec,
                    "memory_delta_mb": r.memory_delta_mb,
                    "success_rate": r.success_rate,
                    "performance_rating": r.details.get("performance_rating") or r.details.get("cache_rating") or r.details.get("memory_rating") or "Unknown"
                }
                for r in self.results
            ]
        }


def main():
    """Main entry point for the performance benchmark suite."""
    print("‚ö° PERFORMANCE BENCHMARK SUITE")
    print("Validating 80% performance improvement claims...")
    print("=" * 60)
    
    benchmark_suite = PerformanceBenchmarkSuite()
    
    try:
        report = benchmark_suite.run_all_benchmarks()
        
        if "error" in report:
            print(f"‚ùå Benchmarks failed: {report['error']}")
            return 1
        
        # Save detailed report
        report_path = Path(__file__).parent / "performance_benchmark_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2)
        
        print(f"\nüìã Detailed benchmark report saved to: {report_path}")
        
        # Performance summary
        assessment = report["overall_assessment"]
        improvement = report["improvement_validation"]
        
        print(f"\nüéØ PERFORMANCE ASSESSMENT")
        print("=" * 60)
        print(f"Overall Performance Score: {assessment['performance_score_percent']:.1f}%")
        print(f"Improvement Targets Met: {improvement['targets_met']}/{improvement['total_targets']} ({improvement['improvement_score_percent']:.1f}%)")
        print(f"System Rating: {assessment['system_rating']}")
        
        # Show key metrics
        if "theme_switching" in report["performance_analysis"]:
            theme_data = report["performance_analysis"]["theme_switching"]
            print(f"Theme Switching: {theme_data['avg_time_ms']:.1f}ms avg ({'‚úÖ' if theme_data['meets_target'] else '‚ùå'})")
        
        if "cache_efficiency" in report["performance_analysis"]:
            cache_data = report["performance_analysis"]["cache_efficiency"]
            print(f"Cache Hit Rate: {cache_data['hit_rate_percent']:.1f}% ({'‚úÖ' if cache_data['meets_target'] else '‚ùå'})")
        
        # Return based on performance
        if improvement["improvement_score_percent"] >= 75:
            print("\nüéâ Performance benchmarks confirm significant improvements!")
            return 0
        elif improvement["improvement_score_percent"] >= 50:
            print("\n‚ö†Ô∏è  Performance improvements partially validated.")
            return 1
        else:
            print("\n‚ùå Performance targets not met.")
            return 2
            
    except KeyboardInterrupt:
        print("\n‚ùå Benchmarks interrupted by user")
        return 3
    except Exception as e:
        print(f"\nüí• Benchmarks failed: {e}")
        return 4


if __name__ == "__main__":
    sys.exit(main())